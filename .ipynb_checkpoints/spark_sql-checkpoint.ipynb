{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7e0615-2557-4cc3-8cdc-8f8f9bf021a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, lit\n",
    "from pyspark.sql.types import BooleanType\n",
    "from pyspark.sql.functions import pandas_udf\n",
    "from functools import reduce\n",
    "import time\n",
    "import gc\n",
    "\n",
    "from models.cnn import CNN\n",
    "\n",
    "import base64\n",
    "import io\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "from tabulate import tabulate\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec11c1e1-d054-4511-ba14-5974430fd7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH_PYTORCH = \"models/fraud_cnn.pt\"\n",
    "MODEL_PATH_TENSORFLOW = \"models/efficientNet.h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ce854d-0c81-45dd-a118-078ac10232d1",
   "metadata": {},
   "source": [
    "## Create Spark session and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064fd290-9dce-44f9-a3c2-e8e46bb7ecc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"FraudModelInference_Tables\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b680b5-7f9f-4201-a559-387d10663c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "idimage_df = spark.read.option(\"header\", True).csv(\"data/idimage_fixed.csv\")\n",
    "idlabel_df = spark.read.option(\"header\", True).csv(\"data/idlabel.csv\")\n",
    "idmeta_df = spark.read.option(\"header\", True).csv(\"data/idmeta.csv\")  \n",
    "#spark action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5b6c34-390c-4507-9aa7-645e4181e4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change isfraud column datatype to Bool\n",
    "idlabel_df = idlabel_df.withColumn(\"isfraud\", col(\"isfraud\").cast(BooleanType()))   #Transformation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eaad2b0-0f0d-4a9c-9e90-0004fb3b631d",
   "metadata": {},
   "source": [
    "# Register all tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6d2ce2-1321-48c3-a98e-66cf9a486bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "idimage_df.createOrReplaceTempView(\"idimage\")\n",
    "idlabel_df.createOrReplaceTempView(\"idlabel\")\n",
    "idmeta_df.createOrReplaceTempView(\"idmeta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36f32dd-b041-473a-b5c5-aeb12af349dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to duplicate the data\n",
    "def duplicate_df(df, n):\n",
    "    dfs = [df.withColumn(\"dup_batch\", lit(i)) for i in range(n)]\n",
    "    return reduce(lambda a, b: a.unionByName(b), dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b43fde8-ce0b-4fda-a8ce-104417af86b8",
   "metadata": {},
   "source": [
    "# Load model from saved weights (CNN(100), EfficientNet (81%))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87ae0a9-3de8-4f08-93d7-6a8ba1916868",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Select which model you want to load:\")\n",
    "print(\"1. PyTorch CNN (.pt file)\")\n",
    "print(\"2. Keras Model (.h5 file)\")\n",
    "\n",
    "model_choice = input(\"Enter 1 or 2: \").strip()\n",
    "\n",
    "model = None  \n",
    "\n",
    "if model_choice == '1':\n",
    "    try:\n",
    "        model = CNN()\n",
    "        model.load_state_dict(torch.load(MODEL_PATH_PYTORCH, map_location=torch.device('cpu')))\n",
    "        model.eval()\n",
    "        broadcast_model = spark.sparkContext.broadcast(model)\n",
    "        print(\"PyTorch CNN model loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading PyTorch model: {e}\")\n",
    "        model = None\n",
    "\n",
    "elif model_choice == '2':\n",
    "    try:\n",
    "        model = load_model(MODEL_PATH_KERAS)\n",
    "        print(\"Keras model loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading Keras model: {e}\")\n",
    "        model = None\n",
    "\n",
    "else:\n",
    "    print(\"Invalid input. Please enter 1 or 2.\")\n",
    "    model = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56312250-9a57-45bb-8740-9b6767a0a2bd",
   "metadata": {},
   "source": [
    "Function to preprocess imagepath before sending it to model for input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df582c4-abce-482c-9262-3ce02ccd027b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(base64_str):\n",
    "    try:\n",
    "        image_data = base64.b64decode(base64_str)\n",
    "        image = Image.open(io.BytesIO(image_data)).convert(\"RGB\")\n",
    "        image = image.resize((128, 128))  \n",
    "        image_array = np.array(image) / 255.0  \n",
    "        image_array = np.expand_dims(image_array, axis=0)  \n",
    "        image_array = image_array.transpose((0, 3, 1, 2)) \n",
    "        image_tensor = torch.from_numpy(image_array).float()\n",
    "        \n",
    "        return image_tensor\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Preprocessing failed: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18253e2e-2241-4fc0-a7c3-3f0bc99de5cc",
   "metadata": {},
   "source": [
    "DEFINING an REGISTERING UDF in SPARK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c154803b-ccae-4b2c-a64a-5bd836dc1159",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pandas_udf(BooleanType())\n",
    "def cnn_fraud_detector(image_col: pd.Series) -> pd.Series:\n",
    "    mdl = broadcast_model.value\n",
    "    results = []\n",
    "    for base64_str in image_col:\n",
    "        if mdl is None:\n",
    "            results.append(False)\n",
    "            continue\n",
    "        try:\n",
    "            img_bytes = base64.b64decode(base64_str)\n",
    "            img = Image.open(io.BytesIO(img_bytes)).convert(\"RGB\").resize((128,128))\n",
    "            arr = np.array(img) / 255.0\n",
    "            arr = np.expand_dims(arr, 0).transpose((0,3,1,2))\n",
    "            tensor = torch.from_numpy(arr).float()\n",
    "            with torch.no_grad():\n",
    "                out = mdl(tensor)\n",
    "            results.append(bool(out[0][0] > 0.5))\n",
    "        except Exception:\n",
    "            results.append(False)\n",
    "    return pd.Series(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f4eb08-744d-4ff0-930b-6c8e8bfe9226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fraud_udf = udf(cnn_fraud_detector)\n",
    "\n",
    "spark.udf.register(\"cnn_fraud_udf\", cnn_fraud_detector)\n",
    "\n",
    "spark.udf.register(\"cnn_fraud_detector_sql\", cnn_fraud_detector)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3757b25d-fe44-4ff7-b98a-719fd709e731",
   "metadata": {},
   "source": [
    "# Schema of tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f61fa8-5290-42c2-8b20-41e6acccaa04",
   "metadata": {},
   "source": [
    "idimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7287a335-2d2b-47d3-a37b-357b7026bdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "idimage_schema = spark.sql(\"\"\"\n",
    "    SELECT * FROM idimage LIMIT 0;\n",
    "\"\"\")\n",
    "\n",
    "idimage_schema.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34f9e5a-5df5-4d7e-99ec-b7253714b540",
   "metadata": {},
   "source": [
    "idlabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400380a4-aa1f-4dd2-be63-6756450712db",
   "metadata": {},
   "outputs": [],
   "source": [
    "idlabel_schema = spark.sql(\"\"\"\n",
    "    SELECT * FROM idlabel LIMIT 0;\n",
    "\"\"\")\n",
    "idlabel_schema.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee54aaef-e18d-451b-993d-fb9858129315",
   "metadata": {},
   "source": [
    "idmeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a0af76-6692-459f-be5e-cfc949528381",
   "metadata": {},
   "outputs": [],
   "source": [
    "idmeta_schema = spark.sql(\"\"\"\n",
    "    SELECT * FROM idmeta LIMIT 0;\n",
    "\"\"\")\n",
    "idmeta_schema.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff97fb1-2809-439d-a3be-90428d7d78d0",
   "metadata": {},
   "source": [
    "# making scaled datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7271b365-892f-489f-87fe-72489541b879",
   "metadata": {},
   "outputs": [],
   "source": [
    "scales = [(\"original\", 1), (\"5x\", 5), (\"10x\", 10), (\"20x\", 20), (\"50x\", 50)]\n",
    "for name, factor in scales:\n",
    "    if factor == 1:\n",
    "        img_df, lbl_df, meta_df = idimage_df, idlabel_df, idmeta_df\n",
    "    else:\n",
    "        img_df  = duplicate_df(idimage_df, factor)\n",
    "        lbl_df  = duplicate_df(idlabel_df, factor)\n",
    "        meta_df = duplicate_df(idmeta_df, factor)\n",
    "    img_df.createOrReplaceTempView(f\"idimage_{name}\")\n",
    "    lbl_df.createOrReplaceTempView(f\"idlabel_{name}\")\n",
    "    meta_df.createOrReplaceTempView(f\"idmeta_{name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a708d0-2b25-46b4-b861-8185e855c9ec",
   "metadata": {},
   "source": [
    "# SQL QUEREIS TO GET INSIGHTS FROM DATASETS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9525426d-a739-41ce-b3b0-f4a675c77ff0",
   "metadata": {},
   "source": [
    "Total IDs and Predicted Fraud Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d008f162-cc4c-4b2d-9c2c-a083345abfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = {\n",
    "    \"fraud_predicted\": \"\"\"\n",
    "        SELECT\n",
    "            COUNT(*) AS total_ids,\n",
    "            SUM(CASE WHEN cnn_fraud_detector_sql(imageData) THEN 1 ELSE 0 END) AS fraud_predicted,\n",
    "            100.0 * SUM(CASE WHEN cnn_fraud_detector_sql(imageData) THEN 1 ELSE 0 END) / COUNT(*) AS fraud_rate_percentage\n",
    "        FROM {image_table}\n",
    "    \"\"\",\n",
    "\n",
    "    \"fraud_ground_truth\": \"\"\"\n",
    "        SELECT\n",
    "            COUNT(*) AS total_ids,\n",
    "            SUM(CASE WHEN isfraud THEN 1 ELSE 0 END) AS total_fraud,\n",
    "            SUM(CASE WHEN NOT isfraud THEN 1 ELSE 0 END) AS total_nonfraud,\n",
    "            100.0 * SUM(CASE WHEN isfraud THEN 1 ELSE 0 END) / COUNT(*) AS fraud_percentage\n",
    "        FROM {label_table}\n",
    "    \"\"\",\n",
    "\n",
    "    \"fraud_pattern_ethnicity_wise\": \"\"\"\n",
    "        SELECT\n",
    "            m.ethnicity,\n",
    "            COUNT(*) AS total_customers,\n",
    "            SUM(CASE WHEN cnn_fraud_detector_sql(i.imageData) THEN 1 ELSE 0 END) AS predicted_fraud,\n",
    "            100.0 * SUM(CASE WHEN cnn_fraud_detector_sql(i.imageData) THEN 1 ELSE 0 END) / COUNT(*) AS fraud_rate_pct\n",
    "        FROM {image_table} i\n",
    "        JOIN {label_table} l\n",
    "          ON i.name = l.id\n",
    "        JOIN {meta_table} m\n",
    "          ON l.id = m.id\n",
    "        GROUP BY m.ethnicity\n",
    "        ORDER BY fraud_rate_pct DESC\n",
    "        LIMIT 10\n",
    "    \"\"\",\n",
    "\n",
    "    \"fraud_rate_by_veteran_status\": \"\"\"\n",
    "        SELECT\n",
    "            m.is_veteran,\n",
    "            COUNT(*) AS total_individuals,\n",
    "            SUM(CASE WHEN cnn_fraud_detector_sql(i.imageData) THEN 1 ELSE 0 END) AS predicted_fraud,\n",
    "            100.0 * SUM(CASE WHEN cnn_fraud_detector_sql(i.imageData) THEN 1 ELSE 0 END) / COUNT(*) AS fraud_rate_pct\n",
    "        FROM {image_table} i\n",
    "        JOIN {label_table} l\n",
    "          ON i.name = l.id\n",
    "        JOIN {meta_table} m\n",
    "          ON l.id = m.id\n",
    "        GROUP BY m.is_veteran\n",
    "        ORDER BY fraud_rate_pct DESC\n",
    "        LIMIT 10\n",
    "    \"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3a238a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_labels = [s[0] for s in scales]\n",
    "print(scale_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829c5e08-0c9a-40a4-ae28-35e4a010d344",
   "metadata": {},
   "source": [
    "# Running for different size of same dataset and saving time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60234bda-bd5c-4634-81d9-1ca38a614914",
   "metadata": {},
   "outputs": [],
   "source": [
    "timings = {\n",
    "    'fraud_predicted': {'spark': [], 'pandas': []},\n",
    "    'fraud_ground_truth': {'spark': [], 'pandas': []},\n",
    "    'fraud_pattern_ethnicity_wise': {'spark': [], 'pandas': []},\n",
    "    'fraud_rate_by_veteran_status': {'spark': [], 'pandas': []}\n",
    "}\n",
    "\n",
    "for scale_name, _ in scales:\n",
    "    img_tbl  = f\"idimage_{scale_name}\"\n",
    "    lbl_tbl  = f\"idlabel_{scale_name}\"\n",
    "    meta_tbl = f\"idmeta_{scale_name}\"\n",
    "\n",
    "    for qname, qsql in queries.items():\n",
    "        # format in the three table names\n",
    "        sql = qsql.format(\n",
    "            image_table=img_tbl,\n",
    "            label_table=lbl_tbl,\n",
    "            meta_table=meta_tbl\n",
    "        )\n",
    "        start = time.time()\n",
    "        spark.sql(sql).collect()\n",
    "        timings[qname][\"spark\"].append(time.time() - start)\n",
    "\n",
    "    print(f\"==== {scale_name} done ====\")\n",
    "    spark.catalog.clearCache()\n",
    "    gc.collect()\n",
    "    spark.sparkContext._jvm.java.lang.System.gc()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5210a0-f14e-4ab5-bc22-77531a55cd02",
   "metadata": {},
   "source": [
    "PLOTTING THE GRAPHS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03174ff8-9fdf-46f5-80de-867b912c0e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xticks = [0, 10, 20, 30, 40, 50]\n",
    "scale_values = [1, 5, 10, 20, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13a5e22-b493-4647-b789-081b2972c875",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for qname, times in timings.items():\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(scale_values, times, marker='o')\n",
    "    plt.xlabel('Data Scale')\n",
    "    plt.ylabel('Execution Time (s)')\n",
    "    plt.title(f'Execution Time vs Scale for: {qname}')\n",
    "    plt.grid(which='both', ls='--', linewidth=0.5)\n",
    "    plt.xticks(ticks=xticks)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"plots/spark/{qname}_spark.png\")  \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab040d4-0ae2-4097-9159-4c8479956117",
   "metadata": {},
   "outputs": [],
   "source": [
    "header = [\"Query\"] + [s[0] for s in scales]\n",
    "rows = []\n",
    "for qname, times in timings.items():\n",
    "    rows.append([qname] + [f\"{t:.2f}\" for t in times])\n",
    "\n",
    "print(\"\\n=== Query Execution Times (seconds) ===\")\n",
    "print(tabulate(rows, headers=header, tablefmt=\"github\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b362f88-424a-43ed-88fe-d857536a547b",
   "metadata": {},
   "source": [
    "## USING PANDAS AND COMPARIING IT WITH SPARK+UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55071575-6972-4915-87cd-a3ab9899ed06",
   "metadata": {},
   "outputs": [],
   "source": [
    "idimage_df = pd.read_csv(\"data/idimage_fixed.csv\")\n",
    "idlabel_df = pd.read_csv(\"data/idlabel.csv\")\n",
    "idmeta_df  = pd.read_csv(\"data/idmeta.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed225e1-be71-4fd2-8c9b-dcbe20973613",
   "metadata": {},
   "outputs": [],
   "source": [
    "idlabel_df['isfraud'] = idlabel_df['isfraud'].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1229311-a15c-41dc-81c3-4383bdfbd6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_fraud(image_b64):\n",
    "    try:\n",
    "        img_bytes = base64.b64decode(image_b64)\n",
    "        img = Image.open(io.BytesIO(img_bytes)).convert(\"RGB\").resize((128, 128))\n",
    "        arr = np.array(img) / 255.0\n",
    "        arr = np.expand_dims(arr, 0).transpose((0, 3, 1, 2))\n",
    "        tensor = torch.from_numpy(arr).float()\n",
    "        with torch.no_grad():\n",
    "            out = model(tensor)\n",
    "        return bool(out[0][0] > 0.5)\n",
    "    except Exception:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29982010-9eda-4272-9b53-3bcc56a00d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fraud_predicted(image_df):\n",
    "    image_df = image_df.copy()\n",
    "    image_df['predicted_fraud'] = image_df['imageData'].apply(predict_fraud)\n",
    "    total_ids = len(image_df)\n",
    "    fraud_predicted = image_df['predicted_fraud'].sum()\n",
    "    fraud_rate_percentage = 100.0 * fraud_predicted / total_ids\n",
    "    return {\n",
    "        'total_ids': total_ids,\n",
    "        'fraud_predicted': fraud_predicted,\n",
    "        'fraud_rate_percentage': fraud_rate_percentage\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e806d8-ba57-4abe-8e40-0a298007d820",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fraud_ground_truth(label_df):\n",
    "    total_ids = len(label_df)\n",
    "    total_fraud = label_df['isfraud'].sum()\n",
    "    total_nonfraud = total_ids - total_fraud\n",
    "    fraud_percentage = 100.0 * total_fraud / total_ids\n",
    "    return {\n",
    "        'total_ids': total_ids,\n",
    "        'total_fraud': total_fraud,\n",
    "        'total_nonfraud': total_nonfraud,\n",
    "        'fraud_percentage': fraud_percentage\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2de95f-cb18-43f7-950d-3a551c97407f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fraud_pattern_ethnicity_wise(image_df, label_df, meta_df):\n",
    "    image_df = image_df.copy()\n",
    "    image_df['predicted_fraud'] = image_df['imageData'].apply(predict_fraud)\n",
    "    merged_df = image_df.merge(label_df, left_on='name', right_on='id')\n",
    "    merged_df = merged_df.merge(meta_df, on='id')\n",
    "    group = merged_df.groupby('ethnicity').agg(\n",
    "        total_customers=('id', 'count'),\n",
    "        predicted_fraud=('predicted_fraud', 'sum')\n",
    "    ).reset_index()\n",
    "    group['fraud_rate_pct'] = 100.0 * group['predicted_fraud'] / group['total_customers']\n",
    "    return group.sort_values('fraud_rate_pct', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a99aea6-d606-4337-a835-488c13fa295c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fraud_rate_by_veteran_status(image_df, label_df, meta_df):\n",
    "    image_df = image_df.copy()\n",
    "    image_df['predicted_fraud'] = image_df['imageData'].apply(predict_fraud)\n",
    "    merged_df = image_df.merge(label_df, left_on='name', right_on='id')\n",
    "    merged_df = merged_df.merge(meta_df, on='id')\n",
    "    group = merged_df.groupby('is_veteran').agg(\n",
    "        total_individuals=('id', 'count'),\n",
    "        predicted_fraud=('predicted_fraud', 'sum')\n",
    "    ).reset_index()\n",
    "    group['fraud_rate_pct'] = 100.0 * group['predicted_fraud'] / group['total_individuals']\n",
    "    return group.sort_values('fraud_rate_pct', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20551a1-ab2b-4b28-b825-3a410bb72aad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3326fe4-abdd-4aac-9e55-986aa4a82219",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for scale_name, factor in scales:\n",
    "    # print(f\"=== {scale_name} Done===\")\n",
    "    \n",
    "    img_df_scaled = pd.concat([idimage_df] * factor, ignore_index=True)\n",
    "    lbl_df_scaled = pd.concat([idlabel_df] * factor, ignore_index=True)\n",
    "    meta_df_scaled = pd.concat([idmeta_df] * factor, ignore_index=True)\n",
    "    \n",
    "    # Measure Pandas execution times\n",
    "    start = time.time()\n",
    "    fraud_predicted(img_df_scaled)\n",
    "    timings['fraud_predicted']['pandas'].append(time.time() - start)\n",
    "    \n",
    "    start = time.time()\n",
    "    fraud_ground_truth(lbl_df_scaled)\n",
    "    timings['fraud_ground_truth']['pandas'].append(time.time() - start)\n",
    "    \n",
    "    start = time.time()\n",
    "    fraud_pattern_ethnicity_wise(img_df_scaled, lbl_df_scaled, meta_df_scaled)\n",
    "    timings['fraud_pattern_ethnicity_wise']['pandas'].append(time.time() - start)\n",
    "    \n",
    "    start = time.time()\n",
    "    fraud_rate_by_veteran_status(img_df_scaled, lbl_df_scaled, meta_df_scaled)\n",
    "    timings['fraud_rate_by_veteran_status']['pandas'].append(time.time() - start)\n",
    "    \n",
    "    print(f\"=== {scale_name} Done===\")\n",
    "    \n",
    "    spark.catalog.clearCache()\n",
    "    gc.collect()\n",
    "    spark.sparkContext._jvm.java.lang.System.gc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef27fed6-3f4b-4810-bf5c-b0c399b91b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "xticks = [0, 10, 20, 30, 40, 50]\n",
    "scale_values = [1, 5, 10, 20, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc6d3ab-59e6-4af0-b7b9-28e3015cc831",
   "metadata": {},
   "outputs": [],
   "source": [
    "for query_name in timings:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(scale_values, timings[query_name]['pandas'], marker='s', label='Pandas')\n",
    "    plt.xlabel('Data Scale')\n",
    "    plt.ylabel('Execution Time (s)')\n",
    "    plt.title(f'Execution Time vs Data Scale for {query_name}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.xticks(xticks)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"plots/pandas/{query_name}_pandas.png\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc27d40-2477-47e6-901e-7db7a79a9ccc",
   "metadata": {},
   "source": [
    "PLOTTING BOTH PANDAS AND SPARK_UDF TIME ON SAME PLOT FOR BETTER COMPARISION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e825a448-0521-4be2-9627-503327c799f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for qname in timings:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(scale_values, timings[qname]['spark'], marker='o', color='tab:blue',  label='Spark + UDF')\n",
    "    plt.plot(scale_values, timings[qname]['pandas'], marker='s', color='tab:red', linewidth=2, label='Pandas')\n",
    "    plt.xlabel('Data Scale')\n",
    "    plt.ylabel('Execution Time (s)')\n",
    "    plt.title(f'Execution Time vs Scale for: {qname}')\n",
    "    plt.yscale('log')\n",
    "    plt.grid(which='both', ls='--', linewidth=0.5)\n",
    "    plt.legend()\n",
    "    plt.xticks(xticks=xticks)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"plots/combined/{qname}_combined.png\")  \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70260da-3826-4040-a8c1-85c1da5560c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Pandas Query Execution Times (seconds) ===\")\n",
    "\n",
    "header = [\"Query\"] + scale_labels\n",
    "rows = [\n",
    "    [qname] + [f\"{t:.2f}\" for t in timings[qname][\"pandas\"]]\n",
    "    for qname in timings\n",
    "]\n",
    "\n",
    "print(tabulate(rows, headers=header, tablefmt=\"github\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ac476a-caba-420d-8375-d15506a45a01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b4f98e-6080-4e12-be34-0c1145a20a1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
